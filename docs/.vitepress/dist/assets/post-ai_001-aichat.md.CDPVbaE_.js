import{_ as a,c as e,o as t,a3 as i}from"./chunks/framework.Bsyxd66g.js";const o="/assets/image-20240708172247219._KamroGm.png",l="/assets/image_3.CWQQBrYD.png",r="/assets/image_2.C5ZbVxKF.png",s="/assets/image_1.BKnx5IPO.png",x=JSON.parse('{"title":"AI Chat 体验","description":"","frontmatter":{},"headers":[],"relativePath":"post-ai/001-aichat.md","filePath":"post-ai/001-aichat.md","lastUpdated":1720496026000}'),p={name:"post-ai/001-aichat.md"},n=i('<h1 id="ai-chat-体验" tabindex="-1">AI Chat 体验 <a class="header-anchor" href="#ai-chat-体验" aria-label="Permalink to &quot;AI Chat 体验&quot;">​</a></h1><h3 id="程序介绍" tabindex="-1">程序介绍 <a class="header-anchor" href="#程序介绍" aria-label="Permalink to &quot;程序介绍&quot;">​</a></h3><p>基于 LobeChat 部署的 AI Chat 体验程序，目前已经接入以下模型：</p><ul><li>OpenAI：GPT3.5、GPT4o</li><li>Anthropic：Claude 3.5 Sonnet</li><li>DeepSeek：DeepSeek-V2、DeepSeek-coder-V2</li><li>Google：Gemini 1.5 Flash、Gemini 1.5 Pro</li><li>Groq：LLaMa3-3-70B、Mixtral-8x7b、Gemma-7b-it、LLaMa3-3-8B</li><li>Ollama：qwen2:0.5b 【Ollama 基于私有服务器本地化部署的模型，服务器性能有限，只能运行此小模型了😅】</li></ul><p>AI Chat 供临时体验。</p><p>访问地址：<a href="https://lobe.pmjojo.xyz" target="_blank" rel="noreferrer">https://lobe.pmjojo.xyz</a></p><p>访问密码：pmjojo</p><p><img src="'+o+'" alt="image-20240708172247219"></p><br><h3 id="ollama-使用教程" tabindex="-1">Ollama 使用教程 <a class="header-anchor" href="#ollama-使用教程" aria-label="Permalink to &quot;Ollama 使用教程&quot;">​</a></h3><p>1.点击 Ollama 设置模型前往设置页。</p><p><img src="'+l+'" alt="image_3"></p><br><p>2.点击【清空】按钮，清楚现有的所有模型。</p><p><img src="'+r+'" alt="image_2"></p><br><p>3.选择【qwen2:0.5b】模型，然后回到聊天页面，选择该模型聊天。</p><p><img src="'+s+'" alt="image_1"></p>',18),m=[n];function _(c,h,d,g,b,u){return t(),e("div",null,m)}const A=a(p,[["render",_]]);export{x as __pageData,A as default};
